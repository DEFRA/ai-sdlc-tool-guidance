# Azure AI Foundry - Detailed Guide

*(Generated by AI, on August 6th 2025)*

## What Azure AI Foundry does

Azure AI Foundry is Microsoft's unified cloud platform for designing, building, and running generative AI applications at enterprise scale. It provides access to a comprehensive catalogue of foundation models, enables sophisticated multi-agent workflows, and delivers governance capabilities through a single portal, SDK, and REST API infrastructure. Azure AI Foundry is a key component of Microsoft's AI strategy, focused on enterprise-grade AI deployment within Azure's secure cloud environment.

| Key feature | What it does | Benefits |
|-------------|-------------|----------|
| **Model Catalogue Access** | Provides access to Azure OpenAI models, open-source models from Hugging Face, Meta, Cohere, and Microsoft's own Phi models | Choose optimal models for specific tasks with standardised deployment and management |
| **Agent Service & Orchestration** | Orchestrates multi-step AI agent workflows with tools like browser automation, code interpretation, and function calling | Build sophisticated AI applications that can perform complex reasoning and actions |
| **Responsible AI Tooling** | Built-in content safety, bias detection, and responsible AI evaluation frameworks | Deploy AI systems with confidence in safety and compliance |
| **Enterprise Integration** | Seamless integration with Azure services, Microsoft 365, and enterprise data sources | Leverage existing Microsoft infrastructure for AI applications |

You can deploy Azure AI Foundry in different configurations for various organisational needs:

| Deployment option | What it does | Best for |
|------------------|-------------|----------|
| **Standard hub deployment** | Models and agents run in Azure public cloud regions | General enterprise use cases with standard security requirements |
| **Private networking** | Access through Azure Private Link without internet exposure | Enhanced security for sensitive workloads |
| **Customer-managed keys** | Full control over encryption keys through Azure Key Vault | Regulated environments requiring key sovereignty |
| **Local inference (Windows AI Foundry)** | Deploy open-source models on local devices and edge infrastructure | Offline scenarios and strict data residency requirements |

Azure AI Foundry is available across multiple Azure regions, with comprehensive support in UK South and UK West for UK government workloads with data residency requirements. The platform integrates deeply with existing Azure services, allowing you to leverage current Azure infrastructure, security policies, and compliance frameworks when deploying AI solutions.

For UK government use, Azure AI Foundry's appeal includes its robust security posture, data sovereignty options, ISO/IEC 42001:2023 certification for responsible AI, and alignment with Microsoft's existing authority to operate in government environments. The service follows a "shared responsibility model" - Microsoft secures the underlying infrastructure and models, while you secure your data, applications, and AI system configurations.

Website: <https://learn.microsoft.com/azure/ai-foundry/>

## Privacy controls

| Privacy control | What it does | Default setting | Your control |
|-----------------|-------------|----------------|--------------|
| **Model training opt-out** | Ensures your data is not used to train or improve Azure OpenAI and other foundation models | Enabled by default | Organisation-wide control via Azure portal |
| **Private networking** | Access Azure AI Foundry through Azure Private Link without exposing traffic to the public internet | Optional | Configuration required |
| **Customer-managed keys** | Full control over encryption keys for data at rest | Optional | Azure Key Vault integration |
| **Agent thread privacy** | Controls data retention and access for AI agent conversation threads | Configurable retention | Customer-controlled deletion APIs |

Azure AI Foundry is designed with **privacy by default** principles, particularly following Microsoft's achievement of ISO/IEC 42001:2023 certification in July 2025. A fundamental privacy control is that, by default, **your data is not used to train or improve the foundation models** in Azure AI Foundry. Microsoft makes this commitment explicit in their documentation and service terms, treating your inputs (prompts) and outputs (model responses) as your content under the Azure shared responsibility model.

The platform provides multiple layers of privacy control beyond this default stance. For network-level privacy, you can configure **Azure Private Link** to access Azure AI Foundry services via private endpoints, ensuring your traffic never traverses the public internet. This is particularly valuable for government workloads processing sensitive data, as it eliminates potential exposure points on the public internet.

For organisations handling highly regulated data, Azure AI Foundry supports **customer-managed keys (CMK)** through Azure Key Vault integration. This provides complete control over encryption keys, including the ability to rotate keys, establish usage policies, or revoke access by disabling keys. The service maintains this encryption across all data stores including model fine-tuning datasets, agent conversation threads, and knowledge base content.

Azure AI Foundry's **Agent Service** includes sophisticated privacy controls for conversation threads and files. Administrators can configure retention policies for agent interactions, and data is only persisted until explicitly deleted through customer-controlled APIs. This aligns with data minimisation principles while enabling the stateful conversations required for effective AI agents.

For UK government users, these privacy controls align well with obligations for handling citizen data and internal government information, particularly when combined with the UK South/UK West regional deployment options and Microsoft's compliance with UK data protection frameworks.

## Terms of Use and Privacy Policy

| Policy Document | Key Provisions | Last Updated |
|-----------------|----------------|--------------|
| **Microsoft Product Terms** | Governs Azure AI Foundry usage as part of overall Azure services | Regularly updated |
| **Microsoft Products & Services Data Protection Addendum** | Contractual GDPR compliance and data-processing terms | Available with enterprise agreements |
| **Azure AI Services Data Protection Addendum** | Specific terms for AI services data handling, including responsible AI commitments | Available on request |
| **Supplemental Terms for Azure Previews** | Applies to preview features in Azure AI Foundry | Updated with new preview releases |

The use of Azure AI Foundry is governed by several key documents that outline terms of use and privacy implications. The primary agreement is the **Microsoft Product Terms**, which includes specific sections for AI services including Azure AI Foundry. These terms establish that content processed through Azure AI Foundry (inputs and outputs) are owned by the customer, not Microsoft, and clarify Microsoft's limited rights to use this content to provide and maintain the service.

Given that Azure AI Foundry provides access to models from multiple providers (Azure OpenAI, Meta, Cohere, etc.), the platform maintains unified terms while respecting model-specific requirements. Microsoft has negotiated enterprise-friendly terms with model providers, reducing the complexity of managing multiple End User License Agreements compared to accessing models directly from various providers.

The **Microsoft Products & Services Data Protection Addendum** provides comprehensive data protection terms that satisfy GDPR and UK data protection requirements. This document was strengthened following Microsoft's ISO/IEC 42001:2023 certification achievement in 2025, providing additional assurance around responsible AI practices and governance.

For UK government use, these terms have important implications. The standard Microsoft terms establish Microsoft as a processor (not controller) of government data, which supports compliance with data protection regulations. The terms also confirm that intellectual property created through Azure AI Foundry remains the property of the customer â€“ important for government-developed applications or content generated through the service.

The terms explicitly prohibit use of the service to generate illegal or harmful content, consistent with public sector ethical AI use requirements. Microsoft enforces usage limits and implements content safety filters by default, but these can be configured for enterprise users with valid use cases and appropriate governance frameworks.

For audit and compliance needs, the terms clarify that Microsoft maintains logs of Azure AI Foundry requests for security and service improvement, but the content of requests (your data) is protected according to standard Microsoft data handling practices and any specific controls implemented (like private endpoints or customer-managed keys).

Microsoft's comprehensive data protection certifications (including ISO/IEC 27001:2022, SOC 2 Type 2, and the new ISO/IEC 42001:2023 for responsible AI) provide a strong foundation for secure use of Azure AI Foundry in government environments, particularly when deployed in appropriate Azure regions with suitable governance controls.

**Links:**
- [Microsoft Product Terms](https://www.microsoft.com/licensing/terms)
- [Microsoft Privacy Statement](https://privacy.microsoft.com/privacystatement)
- [Microsoft Products & Services Data Protection Addendum](https://aka.ms/dpa)
- [Azure AI Foundry Documentation](https://learn.microsoft.com/azure/ai-foundry/)

## Data Management

### Server Location and Data Residency

| Region | Availability Status | Model Support | Residency Implications |
|--------|---------------------|---------------|------------------------|
| **UK South** | Available | Comprehensive model support including Azure OpenAI | Meets UK data residency requirements |
| **UK West** | Available | Full Azure AI Foundry feature set | UK data sovereignty |
| **EU West (Netherlands)** | Available | Complete model catalogue | EU data residency |
| **US Regions** | Available | Most comprehensive model availability | US jurisdiction |

Azure AI Foundry's server locations align with Microsoft Azure's global regional infrastructure. As of August 2025, Azure AI Foundry is available in multiple Azure regions worldwide, including **UK South** and **UK West** which are particularly relevant for UK government users concerned with data residency. When you use Azure AI Foundry, your data is processed in the Azure region you select for deployment - this includes prompts, custom model data, agent conversation threads, and model outputs.

This regional deployment model is fundamental for data sovereignty considerations. By choosing UK regions, UK government services can ensure that data remains within the UK's borders during processing. Microsoft maintains clear boundaries between regions, and data is not automatically transferred between regions without explicit customer action. This makes it possible to implement strong data residency controls through proper configuration.

The regional deployment model extends to all Azure AI Foundry components including model fine-tuning, agent threads, and knowledge bases. When you fine-tune a model or create AI agents in Azure AI Foundry, the resulting assets are stored in the region where you initiated the process. This comprehensive regional isolation helps satisfy requirements from frameworks like the UK Government Security Classification Policy for handling OFFICIAL and OFFICIAL-SENSITIVE information.

From a legal jurisdiction perspective, data processed in UK regions is subject to UK law, though Microsoft as a US-based company is also subject to US legal requirements. Microsoft addresses this potential conflict through contractual provisions, transparency reports, and established processes for handling government requests for data. The Azure UK government offerings include specific terms designed to address UK public sector requirements.

For cross-border data transfers (which may occur if you choose to deploy in a region outside the UK), Microsoft provides mechanisms compliant with UK GDPR requirements, including Standard Contractual Clauses. These provisions help maintain legal compliance even in multi-region deployments. However, for maximum control, keeping deployments within UK regions is recommended for UK public sector workloads.

Microsoft's approach to regional isolation provides technical and legal separation that supports data residency requirements, making Azure AI Foundry suitable for many UK government use cases when properly configured.

### Data in Transit

| Protection Mechanism | Description | Default Status | Compliance Alignment |
|----------------------|-------------|----------------|----------------------|
| **TLS Encryption** | All API calls and data transfers use TLS 1.2+ | Always enabled | Meets UK NCSC guidance |
| **Private Link** | Private connectivity without internet exposure | Optional configuration | Enhanced security for sensitive workloads |
| **API Request Signing** | Azure AD/Entra authentication on all requests | Required | Prevents request tampering |
| **Certificate Pinning** | Optional additional encryption validation | Available configuration | Higher assurance option |

Azure AI Foundry protects data in transit through comprehensive encryption and secure communication channels. All communication with Azure AI Foundry APIs is encrypted using **Transport Layer Security (TLS)** - specifically TLS 1.2 or higher, aligning with NCSC's guidance for protecting data in transit. This encryption applies to all aspects of the service, including model inference requests, agent interactions, fine-tuning operations, and management API calls.

For enhanced security, Azure AI Foundry can be accessed through **Azure Private Link** using VPC endpoints. This configuration ensures that all traffic between your applications and Azure AI Foundry stays within the Microsoft network and never traverses the public internet, adding an additional layer of protection. Private Link can be particularly valuable for government workloads processing sensitive data, as it reduces the attack surface and prevents potential eavesdropping on the public internet.

Azure AI Foundry also employs Microsoft's standard API authentication using **Azure Active Directory (now Microsoft Entra)**, which authenticates every request and prevents request tampering or replay attacks. All requests must be properly authenticated with valid Azure credentials, ensuring that only authorized systems or users can interact with the service.

When using Azure SDKs to interact with Azure AI Foundry, these security features are automatically implemented, making secure integration straightforward. For custom implementations, Microsoft provides detailed documentation on implementing secure API calls and authentication patterns.

For extremely sensitive government workloads, Azure supports additional transit security controls such as certificate pinning and enhanced network security policies through Azure Policy and Azure Firewall, providing even stronger assurance of endpoint identity and communication security.

The data in transit protections extend to all components of Azure AI Foundry. When using agent conversation threads, knowledge bases, or browser automation tools, all interactions are similarly protected by TLS encryption and can leverage private connectivity options.

For UK government users, these transit controls satisfy requirements for protecting OFFICIAL information in transit when properly implemented, especially when combined with appropriate network security controls and monitoring.

### Data at Rest

| Storage Context | Encryption Mechanism | Key Management Options | Duration |
|-----------------|----------------------|------------------------|----------|
| **Model Inference** | Not stored by default | N/A - transient processing | Temporary processing only |
| **Fine-tuning Datasets** | Azure-managed encryption (AES-256) | Customer-managed keys via Azure Key Vault | Until explicitly deleted |
| **Agent Conversation Threads** | Azure-managed encryption (AES-256) | Customer-managed keys supported | Configurable retention policies |
| **Knowledge Bases** | Azure-managed encryption (AES-256) | Customer-managed keys supported | Until explicitly deleted |
| **Model Evaluation Results** | Azure-managed encryption (AES-256) | Azure system managed | Based on project retention policy |

Azure AI Foundry's approach to data at rest security focuses on minimizing persistent storage and applying strong encryption to any data that is stored. For standard model inference (sending prompts and receiving responses), Azure AI Foundry does not persistently store the content of your requests or the model's responses - data is processed in memory and then discarded unless you explicitly configure logging or enable agent conversation persistence.

For features that do require storage, such as model fine-tuning, agent conversation threads, or knowledge bases, Microsoft applies **encryption at rest using AES-256** as the default. This encryption is implemented through Azure's standard storage layer protections, ensuring that stored data cannot be accessed without proper authorization.

Customers have additional control through integration with **Azure Key Vault** for customer-managed keys (CMK). You can specify customer-managed keys for encrypting fine-tuning datasets, agent conversation threads, and knowledge bases. Using customer-managed keys provides you with direct control over the encryption keys, including the ability to rotate keys, establish key usage policies, or revoke access by disabling the key if needed.

Microsoft's standard key hierarchy and envelope encryption techniques are used to implement this protection, with the actual data encrypted using data keys that are themselves encrypted with your Key Vault master keys. This approach aligns with industry best practices for encryption at rest and supports compliance with strict government security requirements.

When data deletion is required, Azure AI Foundry provides mechanisms to delete custom models, fine-tuning datasets, agent threads, and knowledge bases. According to Microsoft's standard data deletion practices, once deleted, the data becomes inaccessible and is securely wiped during normal storage media lifecycle processes.

For service logs that might contain metadata about your Azure AI Foundry usage (but not the actual content of requests unless configured for logging), Microsoft applies its standard log handling practices, including encryption at rest and defined retention periods.

For UK government users, these data-at-rest controls align with requirements for protecting OFFICIAL information when properly implemented with customer-managed keys. The option to use customer-managed keys provides the control necessary for more sensitive workloads, as it allows government departments to maintain sovereignty over their encryption keys.

## Audit Logging

| Logging Capability | Information Captured | Retention Period | Access Control |
|-------------------|----------------------|------------------|----------------|
| **Azure Activity Log** | Hub and project lifecycle events, configuration changes | User-configurable (default 90 days) | Azure RBAC permissions-based |
| **Azure Monitor Logs** | Model invocations, agent interactions, performance metrics | User-configurable | Azure RBAC permissions-based |
| **Agent Thread Logging** | Optional conversation content and reasoning traces | User-configurable | Customer-controlled retention |
| **Content Safety Logging** | Content filtering actions and policy violations | Integrates with Azure Monitor | Azure RBAC permissions-based |
| **Responsible AI Evaluation** | Model bias assessments and safety evaluation results | Stored until deleted | Hub/project permissions |

Azure AI Foundry integrates with Microsoft Azure's comprehensive logging and monitoring ecosystem to provide audit trails and operational visibility. The primary audit logging mechanism is **Azure Activity Log**, which automatically records all management operations performed on Azure AI Foundry hubs and projects. These logs capture details such as the identity of the user or service principal, the time of the operation, the source IP address, the operation performed, and the result. Activity logs are immutable and can be stored in Azure Storage or Log Analytics with encryption and access controls, making them suitable for compliance and security auditing.

For more detailed operational monitoring, Azure AI Foundry integrates with **Azure Monitor** to provide metrics and logs of model inference operations and agent interactions. These logs can include performance metrics (latency, token usage, request volume) and, if configured, the content of requests and responses. Enabling content logging is optional and controlled by the customer - this allows you to balance audit needs against data minimization principles and privacy requirements.

Azure AI Foundry's **Agent Service** provides sophisticated logging capabilities for conversation threads and agent reasoning processes. When enabled, these logs capture the agent's decision-making process, tool invocations, and conversation flow, which is valuable for both debugging and audit purposes. The recent addition of browser automation tools includes comprehensive logging of web interactions, though this comes with additional security considerations that must be carefully managed.

For content safety and responsible AI governance, Azure AI Foundry automatically logs content filtering actions and policy violations through its integration with Azure AI Content Safety. These logs help track attempted misuse, policy breaches, or content that requires human review, and can be essential for maintaining responsible AI practices and regulatory compliance.

Log access is controlled through **Azure Role-Based Access Control (RBAC)**, allowing you to define precise permissions for who can view or manage logs. For example, you can grant security teams read-only access to Activity logs while restricting access to agent conversation logs. Logs can be exported to security information and event management (SIEM) systems like Microsoft Sentinel for broader security monitoring and correlation.

The retention period for logs is configurable, allowing organizations to implement retention policies that align with their compliance requirements. Logs can be archived in Azure Storage for long-term, cost-effective retention when needed for extended compliance purposes.

For UK government users, these logging capabilities support requirements for audit trails of AI system usage, especially important when AI systems are used for decisions affecting citizens or policy. The granular access controls and immutable nature of Azure Activity logs provide the necessary assurance for demonstrating compliance with usage policies and security requirements.

## Access Controls

| Control Type | Mechanism | Granularity | Integration |
|--------------|-----------|-------------|------------|
| **Azure RBAC** | Role-based access control | Action and resource-level | Azure Active Directory (Entra) |
| **Resource Policies** | Attached directly to hubs and projects | Resource-specific permissions | Azure Policy framework |
| **Conditional Access** | Context-aware access control | User, device, and location-based | Microsoft Entra ID |
| **Managed Identities** | Service-to-service authentication | Eliminates embedded secrets | Azure AD service principals |
| **Network-based Controls** | Private endpoints and network security groups | Network-level restrictions | Azure Virtual Networks |

Azure AI Foundry implements a comprehensive, layered approach to access control based on Microsoft's established Azure Active Directory (now Microsoft Entra) framework. This approach allows organizations to implement the principle of least privilege and segregation of duties for all Azure AI Foundry operations.

The primary access control mechanism is through **Azure Role-Based Access Control (RBAC)** policies attached to users, groups, or service principals. These policies define which Azure AI Foundry actions (APIs) principals can perform and on which resources. The platform provides built-in roles such as *AI Foundry Hub Administrator*, *AI Foundry Project Contributor*, and *AI Foundry User*, while also supporting custom roles for specific organizational needs. For example, you can create roles that allow data scientists to deploy models but restrict fine-tuning capabilities to specific authorized users.

For more specific control at the resource level, Azure AI Foundry supports **Azure Policy** definitions that can be attached directly to hubs, projects, or even individual AI deployments. These policies can enforce security standards such as requiring private endpoints, mandating customer-managed encryption, or restricting model deployments to approved model catalogues.

At an organizational level, **Microsoft Entra Conditional Access** policies can establish sophisticated access controls for Azure AI Foundry based on user risk, device compliance, location, and other contextual factors. These policies can enforce requirements such as multi-factor authentication for administrative operations or restrict access to AI models from unmanaged devices.

For service-to-service authentication, Azure AI Foundry leverages **Azure Managed Identities** to eliminate the need for embedded secrets when Azure AI Foundry components interact with other Azure services. This approach provides secure, automatic credential management and supports both system-assigned and user-assigned managed identities depending on your architectural requirements.

**Network-based access control** adds another layer of protection through Azure Private Link, Network Security Groups, and Azure Firewall policies. These controls can restrict which networks can access Azure AI Foundry services and can be particularly valuable for government environments with strict network segregation requirements.

When using Azure AI Foundry with enterprise knowledge bases and agent interactions, access controls extend to the data sources and conversation threads themselves. This ensures that AI models only access authorized information sources and that agent interactions are appropriately restricted based on user permissions and data classification.

For authentication and identity management, Azure AI Foundry integrates natively with **Microsoft Entra ID** and supports federation with external identity providers through SAML 2.0 and OpenID Connect. This allows government departments to integrate Azure AI Foundry access control with existing identity management systems and enforce requirements like multi-factor authentication and privileged access management.

For UK government users, these comprehensive access controls satisfy requirements for restricting system access based on role and need-to-know principles when properly configured. The ability to enforce network boundaries, integrate with existing identity providers, and maintain detailed audit trails supports alignment with government security frameworks and the NCSC 14 Cloud Security Principles.  

## Compliance and Regulatory Requirements

| Compliance Area | Relevant Certifications/Programs | Scope | Verification |
|-----------------|----------------------------------|-------|-------------|
| **Responsible AI** | ISO/IEC 42001:2023 | Azure AI Foundry Models and Microsoft Security Copilot | Third-party certified (July 2025) |
| **General Security** | ISO/IEC 27001:2022, SOC 2 Type 2 | Azure Global Infrastructure | Third-party audited |
| **UK Government** | UK G-Cloud, NCSC 14 Cloud Security Principles | UK operations | Independently assessed |
| **Data Protection** | GDPR compliance, UK Data Protection Act 2018 | Personal data handling | Contractual commitments |
| **Industry-specific** | HIPAA eligibility, Financial Services compliance | Healthcare and financial data | Assessment available |

Azure AI Foundry benefits from Microsoft Azure's extensive compliance programs and certifications, which provide assurance about the security and compliance posture of the underlying infrastructure. Most significantly, in July 2025, **Azure AI Foundry Models achieved ISO/IEC 42001:2023 certification** - a globally recognized standard for Artificial Intelligence Management Systems. This certification underscores Microsoft's commitment to responsible AI development and provides third-party validation of governance, risk management, and transparency practices.

The ISO/IEC 42001:2023 certification specifically covers Azure AI Foundry Models (including Azure OpenAI models) and demonstrates that Microsoft has implemented robust processes for:
- AI risk management throughout the model lifecycle
- Bias detection and mitigation in AI systems
- Transparency and explainability of AI decisions
- Human oversight and accountability in AI operations
- Continuous monitoring and improvement of AI systems

For UK government specifically, Microsoft Azure has documented alignment with the **NCSC 14 Cloud Security Principles**, which helps government entities assess Azure AI Foundry against required security standards. Microsoft is also listed on the UK Government's G-Cloud Digital Marketplace, indicating that its services have been vetted for government procurement. Azure maintains data centres in the UK (UK South and UK West regions) that support data sovereignty requirements.

Regarding data protection regulations, Microsoft provides comprehensive documentation on **UK GDPR and Data Protection Act 2018 compliance** and offers Data Processing Addendums that address UK-specific legal requirements. The regional deployment model in UK regions supports compliance with data residency requirements that may apply to certain government data processing activities.

For organizations in regulated industries, Azure AI Foundry can be configured to meet various sector-specific requirements:
- **Healthcare**: HIPAA-eligible configurations with Business Associate Agreements
- **Financial Services**: Compliance with FCA requirements and financial data protection standards
- **Education**: Support for educational data privacy requirements and student information protection

The responsible AI capabilities built into Azure AI Foundry, including content safety filters, bias evaluation tools, and explainability features, help organizations meet emerging AI governance requirements. The platform's comprehensive audit logging and access controls support regulatory requirements for accountability and traceability in AI system operations.

Azure AI Foundry inherits Microsoft's broader compliance portfolio, including certifications for **ISO/IEC 27001:2022** (information security management), **SOC 2 Type 2** (security, availability, processing integrity, and confidentiality), and various other standards relevant to government and enterprise use.

> **Note:** Responsibility for end-to-end compliance is shared between Microsoft and the customer. Organizations must configure appropriate policies, retention settings, access controls, and key management to match their specific risk profile and regulatory requirements.

For UK government users, these compliance capabilities provide a strong foundation for deploying AI systems in accordance with emerging AI governance frameworks, data protection laws, and security requirements when properly configured and managed according to organizational policies.

## References

**Microsoft Official Documentation:**
- [Azure AI Foundry Documentation](https://learn.microsoft.com/azure/ai-foundry/)
- [Azure AI Foundry Agent Service](https://learn.microsoft.com/azure/ai-foundry/agents/)
- [Responsible AI with Azure AI Foundry](https://learn.microsoft.com/azure/ai-foundry/responsible-use-of-ai-overview)
- [Azure AI Foundry Security and Compliance](https://learn.microsoft.com/azure/ai-foundry/security/)

**Recent Announcements and Updates:**
- [ISO/IEC 42001:2023 Certification Achievement](https://azure.microsoft.com/en-us/blog/microsoft-azure-ai-foundry-models-and-microsoft-security-copilot-achieve-iso-iec-420012023-certification/) (July 2025)
- [Azure AI Foundry Agent Service Browser Automation Tool](https://devblogs.microsoft.com/foundry/announcing-the-browser-automation-tool-preview-in-azure-ai-foundry-agent-service/) (August 2025)
- [What's New in Azure AI Foundry](https://devblogs.microsoft.com/foundry/whats-new-in-azure-ai-foundry-july-2025) (July 2025)

**Compliance and Trust:**
- [Microsoft Trust Center](https://www.microsoft.com/trust-center)
- [Microsoft Service Trust Portal](https://servicetrust.microsoft.com/)
- [Microsoft Responsible AI Resources](https://www.microsoft.com/ai/tools-practices)
- [Azure Compliance Documentation](https://learn.microsoft.com/azure/compliance/)
