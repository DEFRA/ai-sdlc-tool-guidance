# **Junie (JetBrains AI Coding Agent)**

*(Generated by AI, ChatGPT Deep Research, on July 31st 2025)*  

## **1. Tool Overview**

Junie is an AI-powered coding agent integrated into JetBrains IDEs (initially IntelliJ IDEA Ultimate and select others) . Developed by JetBrains, it acts as an autonomous programming assistant that can perform multi-step development tasks either independently or alongside a developer . Unlike simple code autocompletion tools, Junie can navigate your project, analyse code context, generate and modify code, run tests, and even execute terminal commands as needed . Its primary purpose is to offload routine or repetitive tasks and help with complex coding workflows – for example, it can fix coding style issues, apply refactorings, or create new project files based on a high-level prompt . All changes and results are reported back to the user for review, ensuring the developer stays in control of the final output . Junie is distributed as a plugin (bundled with JetBrains IDE versions 2025.1 and later) and requires a JetBrains AI subscription (free tier or above) to function . (The JetBrains AI subscription also covers the complementary “AI Assistant” features like AI chat and code completion.) Junie’s official webpage is on the JetBrains site , and JetBrains provides documentation and a knowledge base for it . As of 2025, Junie is available in IntelliJ IDEA Ultimate, PyCharm Professional, WebStorm, GoLand, PhpStorm, RubyMine and RustRover, with support for more IDEs planned .

## **2. Privacy Settings**

JetBrains has implemented several settings and controls to help maintain privacy when using Junie (and related AI features):

- **Opt-In Activation:** Cloud-assisted AI features are **disabled by default**. A user must explicitly enable JetBrains AI in their IDE (via the JetBrains AI tool widget) and agree to the JetBrains AI Terms before any code or data is sent out . This opt-in design ensures no code leaves the developer’s machine unless they intend to use the AI service.
    
- **Offline Mode:** JetBrains IDEs support an _offline mode_ for AI, which allows using local AI models instead of cloud services. When offline mode is enabled, all AI inference runs locally, and **no data is sent to JetBrains or any external server** . This is beneficial for sensitive code. However, **Junie is not available in offline mode** – at present it requires cloud-based large language models to operate . (Standard AI Assistant features like code completion can work offline with local models, but the Junie agent’s advanced capabilities are cloud-only.)
    
- **Granular File Exclusion:** Developers can control what project data is exposed to the AI. JetBrains supports an “.aiignore” file in your project, which works similarly to a .gitignore. Any files or directories listed in .aiignore will **not** be sent to the AI models . This enables teams to mark sensitive code, configuration, or secrets to be strictly kept private. Additionally, in the IDE settings one can completely disable AI features for specific projects if needed.
    
- **Data Sharing Opt-In:** By default, JetBrains does **not** collect the contents of your prompts or code for its own analysis. There is an optional setting (Tools | AI Assistant | Data Sharing) where users may opt in to share detailed interaction data with JetBrains to help improve the product . If enabled, the IDE will send prompts and AI responses to JetBrains, but JetBrains treats this data as confidential and does not use it to train AI models or share it externally . This detailed logging is **off unless explicitly enabled** by the user. (General usage metrics, such as which AI features are used and how often, may be collected under the standard usage statistics settings – but those metrics do not include any source code or personal data .)
    
- **Disabling and Removal:** Users remain in full control and can disable Junie or all AI functionality at any time. The AI features are delivered via plugins, so one can uninstall or turn off the _JetBrains AI Assistant_ and _Junie_ plugins in the IDE settings if desired. JetBrains confirms that if AI features are disabled, no code or queries will be sent out from the IDE .

These privacy-oriented settings allow developers (and organisations) to use Junie in a cautious way – for example, working offline for highly classified projects, or only allowing the AI on non-sensitive code, etc. JetBrains’ documentation encourages using offline mode or file exclusion for “privacy-sensitive code or repositories” to maintain control .

## **3. Terms of Use and Privacy Policy**

Use of Junie is governed by JetBrains’ **AI Terms of Service** and the JetBrains Privacy Policy/Notice. Key points from these policies include:

- **AI Terms of Service:** The JetBrains AI Terms (covering both AI Assistant and Junie) make clear that by enabling the service, _the user’s instructions and relevant context (code snippets, file information, etc.) will be sent to third-party AI model providers_ in order to generate results . The terms highlight that **users are responsible for the content they choose to send**, including any sensitive or protected information . This means developers should not input secrets or personal data that they are not comfortable sharing with the AI providers. The Terms also disclaim that AI-generated outputs may be inaccurate and that the user must review them (standard AI usage caveats) . By accepting, the user agrees to these conditions. (Users must accept these Terms via the IDE prompt when first enabling the AI plugin.)
    
- **Privacy Notice:** JetBrains’ general Privacy Notice applies to all its products, including the AI services. JetBrains s.r.o. (based in the Czech Republic) is the data controller for user data and adheres to GDPR principles . The Privacy Notice details what personal data JetBrains collects, how it’s used, and users’ rights. For the AI features, JetBrains emphasizes that it does _not_ collect any source code or chat content unless the user opts in (as described in Section 2) . Any data that is collected (like usage telemetry or optional detailed logs) is handled according to the Privacy Notice and kept confidential . JetBrains also provides a Data Processing Agreement for customers who need one, and is transparent about sub-processors (listing the third-party AI providers and cloud hosts involved) .
    
- **Data Use and Training:** Importantly, JetBrains pledges that **customer code and prompts will not be used to train AI models**, either by JetBrains or by the third-party model providers it integrates . JetBrains only partners with LLM services that contractually agree to the same rule (i.e., no training on your data) . This is explicitly stated in the AI Terms of Service and is a critical assurance for users worried about intellectual property leakage.

All relevant legal documents are available on JetBrains’ website: the [JetBrains AI Terms of Service ], the [JetBrains Privacy Notice ], and the [JetBrains AI Data Collection and Use Policy ]. It’s advisable for any organisation considering Junie to review these in full. In summary, the policies put the onus on the user to use the AI features responsibly (e.g., not sharing secrets inadvertently) but also commit JetBrains to strong privacy safeguards (no data retention or misuse of code, as detailed below).

## **4. Data Management**

### **4.1 Server Location and Data Residency**

Junie’s AI processing is backed by JetBrains’ cloud services. According to JetBrains, the JetBrains AI service operates on **Amazon Web Services (AWS) and Google Cloud** infrastructure, with servers currently located in **the EU, the US, and Asia** . This means when you use Junie (or the AI Assistant), your data might be routed to a data centre in one of those regions. JetBrains has not announced any UK-specific data hosting, so data may leave the UK and be processed in the EU or US. European users’ requests may stay within EU servers, but this isn’t explicitly guaranteed in documentation.

For organisations that have strict data residency or sovereignty requirements (such as parts of UK government), JetBrains offers an **AI Enterprise** solution. AI Enterprise allows the AI services to be deployed in a more controlled environment – including options for on-premises installation or using corporate cloud accounts in preferred regions . This could let an organisation ensure data stays, for example, in a UK-based server or within their own infrastructure. However, it’s important to note that _as of mid-2025, Junie is_ **_not_** _available under the on-premises “AI Enterprise” plan_ . Junie currently requires JetBrains’ cloud connectivity, so organisations cannot yet self-host Junie’s brain. They would either have to use the standard JetBrains cloud service for Junie, or wait until enterprise support for Junie is introduced in future. In summary, data sent to Junie might be processed in non-UK jurisdictions (US/EU/Asia), which may be a consideration for government adoption. JetBrains’ choice of reputable cloud providers (AWS and Google) means those data centers have robust security, but the geographic distribution should be weighed against any location-based data policies within the government.

### **4.2 Data in Transit**

Data in transit between the developer’s machine and JetBrains (and onward to the AI model providers) is protected using encryption. When a user invokes Junie or an AI feature, the IDE first sends the prompt and some context (such as relevant code snippets, file types, framework identifiers) to JetBrains’ AI service, which in turn connects to the chosen LLM . All such communications happen over **TLS-encrypted channels**, ensuring that the code and text are secure while traveling over the internet . JetBrains has stated that it uses TLS 1.2+ for securing data in transit for its AI services , which is in line with industry best practices for confidentiality and integrity of data.

In practical terms, after you enable AI features, your IDE is authenticated with your JetBrains account and communicates with JetBrains cloud endpoints over HTTPS. The snippet of code or query you submit (and additional context the IDE appends) is transmitted to JetBrains servers securely, then forwarded to the AI model (OpenAI, Anthropic, etc.) via their API, also presumably over encrypted channels. The AI’s response is then sent back down the chain to your IDE. At no point is the data sent in plain text. Furthermore, JetBrains claims to only partner with cloud AI providers that meet strict security and privacy standards – for example, providers that will not store or leak your data . This adds an extra layer of assurance for data in transit, as the third-party endpoints handling the requests are bound by agreements to handle the data carefully (e.g., OpenAI’s API has its own data privacy commitments). In summary, data in transit to/from Junie is encrypted (SSL/TLS) and guarded by both technical measures and contractual obligations for confidentiality.

### **4.3 Data at Rest**

By default, JetBrains employs a **“zero data retention”** policy for the AI features, meaning it does **not store your code or prompts** on its servers once the immediate operation is complete . The text of prompts and the AI-generated outputs are processed in memory and streamed to the user, but not written to any persistent storage by JetBrains in normal usage. JetBrains explicitly states: _“No user-submitted data is stored”_ on the JetBrains AI platform after processing . This is a crucial point for privacy – it implies that if you use Junie, JetBrains is not building a database of your code. Each query’s data lives just long enough to get an answer from the model, then it’s discarded.

There are a couple of exceptions/clarifications to this general rule:

- **Temporary Logs for Opt-in Users:** If the user has **opted in** to the detailed data collection (see Privacy Settings above), the content of prompts and responses may be stored temporarily on JetBrains servers. In that case, JetBrains will keep the data (which can include source code and AI replies) for a limited time (up to 30 days) in order to review and improve the AI integration . This data is stored at rest in JetBrains’ secure cloud storage, accessible only to JetBrains’ internal AI development team, and is automatically purged after the retention period . Even during that short retention, JetBrains commits that it is not used to train any models and isn’t shared externally . If a user does **not** opt in, then beyond transient processing, **nothing is retained** on disk at JetBrains side .
    
- **Semantic Index Embeddings:** JetBrains AI offers an optional _codebase indexing and semantic search_ feature to enhance AI context. If a user activates semantic indexing on a project, the IDE will upload the project’s code (in segmented form) to JetBrains servers to create **embeddings** (vector representations of the code) . The **embeddings** (not the raw code) are then stored on JetBrains servers to enable fast semantic searches and context for large projects. These vector embeddings do **not** contain the original code text – they are essentially numerical abstractions of the code’s content . JetBrains indicates that the uploaded code itself is only stored temporarily for the indexing process and then discarded, whereas the resulting embeddings are kept for serving the AI features (and those embeddings are tied to your account/repository and not accessible to others) . In effect, this means some form of your code’s “fingerprint” may reside at rest in JetBrains’ cloud if you use the advanced indexing, but not in human-readable form. If this feature is not used, then no code is stored at rest at all.
    
- **Caching and Quota Data:** In order to enforce usage quotas and performance, JetBrains might keep minimal records like how much of your quota you used, and possibly a cache of recent AI interactions to avoid duplicate requests. The FAQ doesn’t detail caching, but it does mention a progress bar for quota usage . Any such data at rest would likely be limited to metadata (e.g., user X used Y tokens of their monthly quota) rather than actual code content.

From a security standpoint, any data that is stored at rest (even temporarily) on JetBrains servers or their cloud providers is protected by encryption and access controls. AWS and Google Cloud, which JetBrains uses, both offer encryption-at-rest by default for stored data, and JetBrains’ own SOC2-audited practices ensure restricted access (see Compliance section). Thus, even in scenarios where data is at rest (detailed logs or embeddings), it is in an encrypted and controlled state. Still, many users will find comfort in the fact that by default, their code is not lingering on a server once an AI answer is delivered.

### **4.4 Data Retention**

JetBrains’ handling of data retention can be summarised as **no retention by default, short retention if opted-in**:

- For standard usage (no opt-in to extra logging), **no user prompt or code data is retained** on JetBrains systems after the AI operation completes . Each prompt is ephemeral. The AI providers (OpenAI/Anthropic/etc.) likewise are instructed not to store or learn from the data. JetBrains effectively acts as a pass-through, not a data warehouse, in this mode.
    
- If the user **opts in to detailed data collection** for product improvement, data is retained only **for up to 30 days** . JetBrains implements this as a rolling window; data older than 30 days is deleted continuously. This limited retention allows them to debug or analyse how the AI features are being used and where they might be failing. After 30 days, the data is gone from their servers. Even during that retention window, as mentioned, the data is not used to train any AI and is accessible only to JetBrains personnel for specific analysis tasks . Users can withdraw this consent at any time, upon which point detailed logging will stop (and presumably any retained logs will be purged).
    
- For **semantic index embeddings** generated (if that feature is used), JetBrains hasn’t stated a fixed retention period. Those embeddings likely persist as long as the user wants the project indexed (to avoid re-computation) and as long as the AI features are enabled for that project. They are effectively part of the user’s service data. One would assume that if you remove or reinitialize the index, those stored embeddings would be deleted, or if you delete the project from JetBrains AI, its vectors would also be removed. JetBrains did note that uploaded code for indexing is temporary and only the embeddings remain , implying the retention of embeddings is tied to the feature’s use. Organisations concerned about this could decide to avoid the semantic indexing for highly sensitive repositories, or wait for an on-premises version of that feature.
    
- JetBrains also adheres to general data retention policies for personal/account data as outlined in their Privacy Notice. That’s outside the scope of code data, but for completeness: if a user were to delete their JetBrains account or not use the service, any associated personal data would eventually be removed in line with GDPR requirements.

Overall, JetBrains’ approach to retention appears very conservative (which is good for privacy). For government use, the implication is that any code or prompt you send to Junie is not lingering indefinitely on some server. It’s either not stored at all, or only stored fleetingly for debugging if you’ve allowed that. This significantly reduces the risk of sensitive code accumulating in places it shouldn’t. It’s still wise, of course, to only feed the AI with data you’re allowed to (the Terms remind users of this responsibility) – but knowing the system isn’t permanently keeping everything is reassuring.

## **5. Audit Logging**

**Audit logging** refers to the ability to record who did what and when – a feature often desired in enterprise or government contexts for compliance. As of now, Junie does not provide a built-in detailed audit log to the end-user for each action it takes beyond the interactive session context. The Junie tool window in the IDE does show the conversation and steps it is taking (for instance, it may list “Analysing X.java… Running tests… Edited Y.py”) which the developer can observe live. However, this is more of a real-time feedback rather than a persistent audit trail. There isn’t a dedicated log file that an administrator can review later showing all Junie operations across an organisation.

For individual developers, the primary record of Junie’s changes is the version control system. Junie doesn’t automatically commit code; it makes changes in the IDE which the user can review and then commit using Git or other VCS. Those commits, if made, become part of the project history like any normal change (with the human developer as the author, since Junie is acting on their behalf). So in terms of auditing **code changes**, one could rely on commit history and code reviews to see what was introduced, even if an AI helped generate it. Junie also reportedly uses the IDE’s inspections and standard editing APIs , meaning any change it makes triggers the same local notifications as a human edit (for example, undo history, diff views, etc., are all available).

At the **organisation level**, JetBrains has indicated that its enterprise offerings will include more administrative oversight features. The **AI Enterprise** plan (targeted at businesses) mentions _“centralized admin tools”_ and enterprise-grade security . While specifics aren’t fully published, this likely entails that an admin can manage AI usage for all users – possibly including viewing usage statistics or logs of AI queries. It would be reasonable to expect features like audit logging of AI activity (which user used it, how many times, maybe what kinds of actions were done) in a future enterprise console. However, since **Junie is not yet available in the Enterprise (on-prem) plan** , these admin logs would currently apply mostly to AI Assistant usage. Once Junie becomes available for enterprise deployment, one can anticipate JetBrains enabling logging of agent actions in that context so that organisations can audit and trace AI-driven changes.

For now, if UK government developers use Junie under the standard cloud service, audit logging is a gap – there’s no out-of-the-box mechanism for an administrator to retrieve a log of “Junie did X at time Y in project Z”. Mitigations could include internal policies that any AI-suggested code must go through code review, and perhaps disabling Junie for extremely critical code paths. JetBrains has heard security teams’ concerns about AI and is actively working on features to address enterprise needs , so audit logging is likely on the roadmap. It’s advisable to keep an eye on JetBrains’ updates or inquire directly for enterprise features like audit trails. In the interim, organisations could restrict Junie usage to less sensitive environments or ensure that standard auditing (IDE event logs, source control, etc.) covers the necessary oversight.

## **6. Access Controls**

Using Junie in an organisation involves a few layers of access control:

- **Account Authentication and License:** To access Junie, a user must have an active JetBrains IDE license and be signed in with their JetBrains Account that has AI access enabled . JetBrains controls AI feature access via its licensing system – for instance, an admin could decide which developers get an AI Pro subscription. If a user doesn’t have permission, the AI features simply remain unavailable to them. This account-based control means AI usage can be tied to individuals, and potentially deactivated centrally by revoking the AI subscription for that user.
    
- **User Role and Permissions:** Junie runs within the user’s IDE with the same file access permissions as the user. It does not have an independent identity or higher privilege on your system than the developer using it. So if a developer only has read access to a repository, Junie cannot magically write to it either – it operates through the IDE on whatever the user can access. It executes local code (like running tests or commands) as a subprocess of the IDE, under the user’s OS permissions. This is important: Junie **cannot escalate privileges** or access network resources beyond the user’s own rights. That said, if a developer running Junie has high privileges (e.g. root access), Junie could perform powerful actions at their behest. Caution should be used just as with any tool that can execute scripts.
    
- **Developer in the Loop:** JetBrains designed Junie to keep the developer in ultimate control of changes. The agent will propose or make changes, but the developer reviews the diffs and decides to keep or discard them. The FAQ emphasises that Junie _“presents results for your review – all while you stay in control.”_ . It means Junie won’t directly push commits or alter your repository history without your involvement. For example, if Junie creates a new file or refactors code, those modifications appear in your IDE as pending edits. You still need to save them and commit them to version control. There is no functionality for Junie to auto-commit to Git or deploy code on its own. This design acts as a safety net against unintended changes propagating without human oversight (analogous to how Copilot or other code assistants don’t auto-merge code). In the context of the UK government’s concern (e.g., **not allowing an AI to directly commit to git**), Junie aligns well – it does not have an auto-commit capability by default. All code check-ins remain a conscious developer action.
    
- **Project/File Access Controls:** As discussed in Privacy Settings, an organisation or developer can prevent Junie from seeing certain files via .aiignore . This is effectively an access control on the AI’s knowledge. For instance, if a repository has a secret config file or sensitive module, adding it to .aiignore means Junie will not read or send that content to the LLM. Additionally, IDE administrators can configure settings (through IDE policies or pre-configured settings) to default AI features to off, requiring explicit activation per project. It’s possible to imagine in a managed environment, an IT admin could ship IDE configs that disable cloud AI unless a developer enables it for a project and maybe goes through some internal approval.
    
- **Admin Governance:** In an enterprise scenario, JetBrains will allow centralised management. Enterprise admins can integrate JetBrains accounts with single sign-on (for example, using SAML/SSO so that company login policies apply to JetBrains services). They will also have the ability to turn on/off AI features for all users or specific teams. While specifics are scant publicly, the mention of _“enterprise-grade security [and] centralized admin tools”_ in the AI Enterprise plan suggests things like controlling which LLM providers are allowed, setting organisation-wide .aiignore patterns, or monitoring usage . Also, enterprise customers can connect **approved external LLM providers** or on-prem models , which acts as an access control on the model side (e.g., an organisation might choose to only allow an internal model or an Azure OpenAI instance that they manage, rather than the public OpenAI cloud).

In summary, Junie respects standard access controls: it runs with user-level permissions and requires a valid user account. It does not introduce new privileged accounts or services within the developer’s environment. Organisations looking to adopt Junie should ensure developers’ JetBrains accounts are managed (JetBrains has features for organisations to manage multiple licenses/users via their Account Portal). By leveraging the available controls – from license assignments to file-based ignores – an organisation can tightly govern where and how Junie is used. From a policy perspective, one can treat Junie as an assistive tool that _the developer drives_, rather than an autonomous process with a mind of its own. This approach, combined with internal coding policies (e.g., mandatory code reviews for AI-generated changes), can maintain high levels of trust and security in a government setting.

## **7. Compliance and Regulatory Requirements**

JetBrains positions itself as a developer tools company with strong security and privacy practices, which is important for public sector use. Some relevant compliance and standards points:

- **GDPR and Data Protection:** Being based in the EU, JetBrains is fully compliant with the EU General Data Protection Regulation (GDPR) (and by extension the UK GDPR). JetBrains s.r.o. in Prague is the entity responsible for data, and the company’s Privacy Notice reflects GDPR principles like data minimisation, purpose limitation, and users’ rights to access or delete data . For government users, this means JetBrains is used to handling personal data under strict regulations, and any personal data (like user account info or telemetry) will be processed lawfully. In context of Junie, since little personal data is involved aside from maybe a user’s name/email in their account, GDPR compliance mainly reassures that JetBrains will handle any logged data properly and respond to any data subject requests.
    
- **Security Audits (SOC 2):** JetBrains has undergone **SOC 2 Type II** audits . SOC 2 is a widely recognised standard (especially in the US and internationally for cloud service providers) that evaluates organisational controls around security, availability, confidentiality, etc. A SOC 2 Type II report means an independent auditor has verified JetBrains’ controls over a period of time. JetBrains having SOC 2 certification indicates that it has robust internal processes for securing customer data. This would cover aspects like access control to production systems, incident response, encryption practices, and so forth. UK government security assessors will view SOC 2 compliance as a positive sign, although they may still require their own risk assessment.
    
- **ISO Certifications:** JetBrains has not publicly claimed ISO/IEC 27001 certification for its whole organisation (as of the information we have). However, parts of JetBrains (like some products) have been mentioned in context of security standards. The Trust Center documentation and marketing materials imply adherence to ISO-like controls (for example, JetBrains Qodana, a different product, achieved SOC 2 and is likely aligning with ISO27001). While we don’t have confirmation of an ISO 27001 certificate, JetBrains’ SOC 2 and general security posture likely align with many ISO requirements. If formal ISO certification is needed for procurement, this might be worth verifying directly with JetBrains.
    
- **Data Processing Agreements (DPAs):** JetBrains provides a Data Processing Addendum for customers, which is useful for compliance with UK/EU data protection laws when a customer is a data controller using JetBrains as a processor. In the AI context, if any personal data were to be input into the prompts (not typical, but possible), the DPA would contractually ensure JetBrains handles it per GDPR standards. JetBrains also publishes a list of sub-processors (third-party services) it uses, along with their locations . Reviewing that list, especially for the AI service, would show which cloud providers and AI API providers are involved (likely AWS in EU/US, Google Cloud in EU/US, OpenAI in US, Anthropic in US, etc.). This transparency helps in compliance checks regarding cross-border data flow (e.g., adequacy for EU-US data transfer – note that as of 2025, a new EU-US Data Privacy Framework exists, but UK has its own transfer provisions too).
    
- **Third-Party Compliance:** The AI service relies on models from OpenAI, Anthropic, Google, etc. Each of these has its own compliance posture. For instance, Google Cloud’s Vertex AI and AWS Bedrock (for Anthropic Claude) are enterprise services with ISO27001, SOC2, and other certifications. OpenAI, which JetBrains uses via API, has stated it doesn’t train on API data and is working on SOC 2 as well. While JetBrains is abstracting these models through its platform, organisations might consider the weakest link. JetBrains’ commitment that providers won’t train on your data covers one aspect , but government users might also ask: are the providers compliant with requirements like not exporting data to certain jurisdictions? JetBrains does restrict usage in certain countries (for example, it notes that due to provider limitations, AI features are not available in some regions like China except through a specific model) , which shows they are mindful of compliance with export controls and local laws. The UK government should ensure any classification of data stays within allowed bounds when using these US-based AI models, even under JetBrains’ contractual assurances.
    
- **On-Premises / Sovereign Option:** Compliance often ties into whether a service can be deemed _secure enough_ or _sovereign_. JetBrains AI Enterprise (once it includes Junie) would allow running the AI stack in an environment controlled by the organisation, potentially solving a lot of regulatory concerns (network isolation, data residency, etc.) . JetBrains already enables connecting to on-prem LLMs via Hugging Face for enterprise users . In a scenario where UK government wanted absolutely no external data sharing, they could use the JetBrains AI platform with a self-hosted model (for example, an LLM running in a government data centre). At this time, they’d lose Junie’s functionality if they did that, but they could still use AI Assistant locally. Over time, we expect JetBrains will make Junie available in offline or enterprise settings as well – which would be key to full adoption in highly regulated environments.
    
- **Other Standards and Regulations:** There’s no indication of specific compliance with standards like FedRAMP (US government) or NHS DSP (UK health) – those typically aren’t relevant to an IDE plugin directly. For most software used by UK government, the concerns revolve around GDPR (covered), handling of official-sensitive data (addressed by privacy controls), and supply chain security. JetBrains’ software is proprietary and widely used; it hasn’t been flagged for supply chain issues to our knowledge. They do have a bug bounty and security team. UK government security architects might also consider compliance with development process guidelines (e.g., does using Junie align with internal coding standards). Since Junie’s suggestions ultimately produce code that goes through normal review, this can be managed within existing frameworks.

In conclusion, JetBrains demonstrates a strong commitment to security and privacy standards – **SOC 2 Type II** compliance , GDPR adherence, and providing tools for data residency control. These are good indicators for suitability in a government context. The main compliance gap right now is the lack of Junie support in an isolated environment, meaning using it involves relying on cloud services outside the UK gov estate. If the data involved is not highly classified, this may be acceptable with proper risk mitigations and agreements. Otherwise, one might delay adoption until an on-prem version is available or use the local-only AI features as an interim measure. JetBrains is likely to continuously improve the compliance aspect as the product matures (especially given enterprise customer feedback).

## **8. References**

- JetBrains IntelliJ IDEA Documentation – **“Junie” Help Page** (May 2025) – _Overview of Junie’s capabilities and compatibility in official JetBrains help._
    
- JetBrains Junie Documentation – **“Getting Started with Junie”** (Jul 2025) – _Introduction to Junie’s functionality, plugin installation, and supported models._
    
- **JetBrains AI FAQ** (JetBrains, 2025) – _Frequently asked questions on JetBrains AI features, including differences between Junie and AI Assistant, offline mode, data handling, and enterprise plans._
    
- **JetBrains AI Terms of Service** (Version 2.0, May 2024) – _Legal terms for using JetBrains AI (Junie/Assistant), highlighting data sharing with third-party LLM providers and user responsibilities._
    
- **JetBrains Privacy Notice** (Jul 2024) – _JetBrains’ general privacy policy, covering data controller details and compliance with GDPR, applicable to all JetBrains services including AI._
    
- JetBrains Documentation – **“Data Collection and Use Policy”** (Jun 2025) – _Detailed description of what data JetBrains AI may collect, how users control it, and the zero-retention approach._
    
- JetBrains Support Knowledge Base – **AI Assistant Privacy/Security Q&A** – _Information from JetBrains support articles confirming no data retention and encryption (TLS 1.2+) for AI data in transit._
    
- **DevClass Tech News – “JetBrains goes live with Junie AI agent…”** (Tim Anderson, Apr 16 2025) – _Article announcing Junie’s production release, with context on free tiers, local vs cloud usage, and initial user feedback._
    
- JetBrains Legal – **“Trust and Security at JetBrains”** – _JetBrains Trust Center information noting SOC 2 Type II certification and GDPR compliance._